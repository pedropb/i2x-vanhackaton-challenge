{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-sequence model to unconcatenate text\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "These are all the modules we'll be using later. Make sure you can import them before proceeding further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import string\n",
    "sys.path.append('../dataset_tools')\n",
    "import dataset_tools\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load text8 dataset\n",
    "\n",
    "For more info on text8 dataset, please visit [this site](http://mattmahoney.net/dc/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified /Users/pedro/vanhack/i2x-challenge/dataset_tools/text8.zip\n",
      "Data size 100000000\n",
      "Word count 17005208\n"
     ]
    }
   ],
   "source": [
    "dataset_file = dataset_tools.maybe_download()\n",
    "text = dataset_tools.read_dict_file(dataset_file)\n",
    "words = text.split(\" \")\n",
    "print(\"Data size %d\" % len(text))\n",
    "print(\"Word count %d\" % len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract input and labels for the dataset\n",
    "\n",
    "The dataset is composed of a series of words from wikipedia articles dump. The text is already in lower case, there is no punctuation and no numbers. Basically, there are only characters from a to z and whitespaces.\n",
    "\n",
    "For this challenge, we have to create a dataset with input and labels like:\n",
    "- X: iwanttogotoberlin\n",
    "- Y: i want to go to berlin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 1700521\n"
     ]
    }
   ],
   "source": [
    "MAX_WORDS_PER_SENTENCE = 10\n",
    "\n",
    "def extract_input_and_labels(words):\n",
    "    def create_xy(fixed_size_words):\n",
    "        return (''.join(fixed_size_words), ' '.join(fixed_size_words))\n",
    "    \n",
    "    return [create_xy(words[i:i+MAX_WORDS_PER_SENTENCE]) \n",
    "            for i in range(0, len(words), MAX_WORDS_PER_SENTENCE)]\n",
    "\n",
    "data = extract_input_and_labels(words)\n",
    "print(\"Data size %d\" % len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some examples:\n",
      "X: sixalbumsothetitlereferstothethreeseven\n",
      "Y: six album so the title refers to the three seven\n",
      "X: wesleyanarminianismfourviewsoneternalsecuritygrandrapidszondervan\n",
      "Y: wesleyan arminianism four views on eternal security grand rapids zondervan\n",
      "X: collationofvaryingmanuscriptsandintheindependentmanuscripttraditions\n",
      "Y: collation of varying manuscripts and in the independent manuscript traditions\n",
      "X: grouptheeritreanpeoplesliberationfronteplftheleadership\n",
      "Y: group the eritrean people s liberation front eplf the leadership\n",
      "X: jrofphiladelphiapennsylvaniaknownbyhisscreenameerifllehhellfire\n",
      "Y: jr of philadelphia pennsylvania known by his screename eriflleh hellfire\n",
      "X: arefromeightzerozeroamonezerozero\n",
      "Y: are from eight zero zero a m one zero zero\n",
      "X: asashootingwarinantarcticabetweenrivaladvertiserszik\n",
      "Y: as a shooting war in antarctica between rival advertisers zik\n",
      "X: fromcrushingobligationandoverworkandfamilyexpectationsandthe\n",
      "Y: from crushing obligation and overwork and family expectations and the\n",
      "X: emmetwalshascaptainbryantwalshliveduptohis\n",
      "Y: emmet walsh as captain bryant walsh lived up to his\n",
      "X: thecourtincludingliberalssuchasfelixfrankfurterhugoblack\n",
      "Y: the court including liberals such as felix frankfurter hugo black\n"
     ]
    }
   ],
   "source": [
    "print(\"Some examples:\")\n",
    "idxs = np.random.randint(0, high=len(data), size=10)\n",
    "for i in idxs:\n",
    "    print(\"X: %s\" % data[i][0])\n",
    "    print(\"Y: %s\" % data[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data\n",
    "\n",
    "Let's see how the lengths of the encoded and decoded sentences are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder_length</th>\n",
       "      <th>decoder_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1700521.000</td>\n",
       "      <td>1700521.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48.806</td>\n",
       "      <td>57.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.004</td>\n",
       "      <td>9.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000</td>\n",
       "      <td>19.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>43.000</td>\n",
       "      <td>52.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.000</td>\n",
       "      <td>57.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54.000</td>\n",
       "      <td>63.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>198.000</td>\n",
       "      <td>207.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       encoder_length  decoder_length\n",
       "count     1700521.000     1700521.000\n",
       "mean           48.806          57.806\n",
       "std             9.004           9.004\n",
       "min            10.000          19.000\n",
       "25%            43.000          52.000\n",
       "50%            48.000          57.000\n",
       "75%            54.000          63.000\n",
       "max           198.000         207.000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "df = pd.DataFrame(data=[[len(d[0]), len(d[1])] for d in data], columns=[\"encoder_length\", \"decoder_length\"])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15aab7b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df[\"encoder_length\"].tolist(), df[\"decoder_length\"].tolist())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the graph above, there are some outliers in this dataset. Our model works with fixed input sizes, so if we accept sentences with such varying lengths, the model training the model.\n",
    "\n",
    "Since we randomly generated the sentences, there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling\n",
    "\n",
    "To improve training, validation and test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Valid and Test split\n",
    "\n",
    "We are doing 80, 10, 10 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, valid, test sizes: 1360417 170052 170052\n"
     ]
    }
   ],
   "source": [
    "train_size = int(round(len(data) * .8))\n",
    "test_size = int(round(len(data) * .1))\n",
    "valid_size = len(data) - train_size - test_size\n",
    "\n",
    "train = data[:train_size]\n",
    "valid = data[train_size:(train_size + valid_size)]\n",
    "test = data[(train_size + valid_size):]\n",
    "\n",
    "print(\"train, valid, test sizes:\", len(train), len(valid), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "Utility functions to map characters to vocabulary IDs and back. We will be using control characters as following:\n",
    "\n",
    "- `#` represents _padding_, i.e., null space inside a string.\n",
    "- `^` represents _go_, i.e., the start of the translated string.\n",
    "- `$` represents _eos_, i.e., the end of a translated string.\n",
    "- ` ` represents _whitespace_.\n",
    "- `?` represents unknown characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 30 3 4\n",
      "a z # ^ $   ?\n"
     ]
    }
   ],
   "source": [
    "CONTROL_CHARS = [\n",
    "    ('#', 0), # PAD\n",
    "    ('^', 1), # GO\n",
    "    ('$', 2), # EOS\n",
    "    (' ', 3), # whitespace\n",
    "    ('?', 4)  # UNK\n",
    "]\n",
    "\n",
    "control_size = len(CONTROL_CHARS)\n",
    "vocabulary_size = len(string.ascii_lowercase) + control_size # [a-z] + CONTROL_CHARS\n",
    "first_letter = ord(string.ascii_lowercase[0])\n",
    "\n",
    "def control_char_by_char(char):\n",
    "    for x in CONTROL_CHARS:\n",
    "        if char == x[0]:\n",
    "            return x\n",
    "    \n",
    "def control_char_by_value(value):\n",
    "    for x in CONTROL_CHARS:\n",
    "        if value == x[1]:\n",
    "            return x\n",
    "\n",
    "def char2id(char):\n",
    "  if char in string.ascii_lowercase:\n",
    "    return ord(char) - first_letter + control_size\n",
    "  elif char in [x[0] for x in CONTROL_CHARS]:\n",
    "    return control_char_by_char(char)[1]\n",
    "  else:\n",
    "    return control_char_by_char('?')[1]\n",
    "  \n",
    "def id2char(dictid):\n",
    "  if dictid >= control_size:\n",
    "    return chr(dictid + first_letter - control_size)\n",
    "  else:\n",
    "    return control_char_by_value(dictid)[0]\n",
    "\n",
    "print(char2id('a'), char2id('z'), char2id(' '), char2id('Ã¯'))\n",
    "print(id2char(5), id2char(30), id2char(0), id2char(1), id2char(2), id2char(3), id2char(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucketing\n",
    "\n",
    "We need buckets, because the length of the input string and translate string differs.\n",
    "\n",
    "Buckets define encoder and decoder sizes, so that we have multiple model, with different, but fixed, input and output sizes.\n",
    "\n",
    "[Read more about buckets](https://www.tensorflow.org/tutorials/seq2seq#bucketing_and_padding)\n",
    "\n",
    "To define how many buckets, and which sizes, we need to explore the dataset a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
